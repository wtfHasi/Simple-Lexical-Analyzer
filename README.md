Simple Lexical Analyzer

This repository contains the implementation of a simple lexical analyzer (also known as a lexer), which tokenizes a source code input into meaningful components, such as keywords, identifiers, literals, operators, and punctuation marks. The lexer processes an input string or file, scans through it character by character, and classifies the characters into distinct token categories based on predefined rules.

Features:
Supports basic tokenization for a subset of programming language syntax.
Identifies keywords, operators, variables, and literals.
Handles common symbols such as parentheses, semicolons, and assignment operators.
Provides a clear output format that displays token type and value.
Usage:
Input a string or file containing source code.
The lexer scans the input and generates a list of tokens.
Each token is categorized and outputted with its type and value.
This lexer serves as a foundational tool for understanding lexical analysis, and can be expanded to support more complex programming languages.
